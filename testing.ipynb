{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MoonBoardRNN.BetaMove.BetaMove import route_to_x_vectors\n",
    "from MoonBoardRNN.GradeNet.grade_net import GradeNet\n",
    "from MoonBoardRNN.BetaMove.BetaMove import classify_and_reorganize_data_ga\n",
    "from MoonBoardRNN.BetaMove.BetaMove import x_vectors_to_matrix\n",
    "from MoonBoardRNN.BetaMove.BetaMove import produce_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoonBoardRoute(mid_holds=[MoonBoardHold(row=11, col=10), MoonBoardHold(row=13, col=5), MoonBoardHold(row=5, col=4)], start_holds=[MoonBoardHold(row=5, col=3)], end_holds=[MoonBoardHold(row=17, col=6)], id=UUID('29d4532f-546f-11ed-8826-b13708a5728f'))\n",
      "[58, 193, 3, 131, 148, 59, -1, -1, -1, -1]\n",
      "MoonBoardRoute(mid_holds=[MoonBoardHold(row=11, col=10), MoonBoardHold(row=13, col=5), MoonBoardHold(row=5, col=4)], start_holds=MoonBoardHold(row=5, col=3), end_holds=MoonBoardHold(row=17, col=6), id=UUID('29d45330-546f-11ed-8826-b13708a5728f'))\n"
     ]
    }
   ],
   "source": [
    "from share.moonboard_util import MoonBoardRoute\n",
    "from MapElites.me_utils import *\n",
    "\n",
    "rand_route = MoonBoardRoute.make_random_valid()\n",
    "params = route_to_ME_params(rand_route)\n",
    "deparasm = ME_params_to_route(params)\n",
    "print(rand_route)\n",
    "print(params)\n",
    "print(deparasm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mMoonBoardRNN\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplotting\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_problem\n\u001b[1;32m      6\u001b[0m TARGET \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mV5\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m net \u001b[39m=\u001b[39m GradeNet()\n\u001b[1;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/GeneticBoulders/MoonBoardRNN/GradeNet/grade_net.py:21\u001b[0m, in \u001b[0;36mGradeNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__model \u001b[39m=\u001b[39m GradeNet\u001b[39m.\u001b[39;49mcreate_model()\n\u001b[1;32m     22\u001b[0m \tdirname \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(\u001b[39m__file__\u001b[39m)\u001b[39m.\u001b[39mparent\n\u001b[1;32m     23\u001b[0m \tfilepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dirname, \u001b[39m'\u001b[39m\u001b[39mGradeNet.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/GeneticBoulders/MoonBoardRNN/GradeNet/grade_net.py:31\u001b[0m, in \u001b[0;36mGradeNet.create_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m inputs \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m22\u001b[39m))\n\u001b[1;32m     30\u001b[0m mask \u001b[39m=\u001b[39m Masking(mask_value\u001b[39m=\u001b[39m\u001b[39m0.\u001b[39m)\u001b[39m.\u001b[39mcompute_mask(inputs)\n\u001b[0;32m---> 31\u001b[0m lstm0 \u001b[39m=\u001b[39m LSTM(\u001b[39m20\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtanh\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m12\u001b[39;49m, \u001b[39m22\u001b[39;49m), kernel_initializer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mglorot_normal\u001b[39;49m\u001b[39m'\u001b[39;49m, return_sequences\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTrue\u001b[39;49m\u001b[39m'\u001b[39;49m)(inputs, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m     32\u001b[0m dense1 \u001b[39m=\u001b[39m Dense(\u001b[39m100\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mglorot_normal\u001b[39m\u001b[39m'\u001b[39m)(lstm0)\n\u001b[1;32m     33\u001b[0m dense2 \u001b[39m=\u001b[39m Dense(\u001b[39m80\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mglorot_normal\u001b[39m\u001b[39m'\u001b[39m)(dense1)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/layers/rnn/base_rnn.py:553\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[1;32m    549\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[1;32m    550\u001b[0m )\n\u001b[1;32m    552\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    555\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:1011\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[39m# on symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\n\u001b[1;32m   1009\u001b[0m     \u001b[39mself\u001b[39m, inputs, args, kwargs, input_list\n\u001b[1;32m   1010\u001b[0m ):\n\u001b[0;32m-> 1011\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(\n\u001b[1;32m   1012\u001b[0m         inputs, args, kwargs, input_list\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:2498\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   2491\u001b[0m         training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[1;32m   2494\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value\n\u001b[1;32m   2495\u001b[0m ):\n\u001b[1;32m   2496\u001b[0m     \u001b[39m# Check input assumptions set after layer building, e.g. input\u001b[39;00m\n\u001b[1;32m   2497\u001b[0m     \u001b[39m# shape.\u001b[39;00m\n\u001b[0;32m-> 2498\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[1;32m   2499\u001b[0m         inputs, input_masks, args, kwargs\n\u001b[1;32m   2500\u001b[0m     )\n\u001b[1;32m   2502\u001b[0m     \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2503\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2504\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2505\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2506\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2507\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:2345\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m   2341\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   2342\u001b[0m         keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature\n\u001b[1;32m   2343\u001b[0m     )\n\u001b[1;32m   2344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(\n\u001b[1;32m   2346\u001b[0m         inputs, args, kwargs, input_masks\n\u001b[1;32m   2347\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:2404\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m   2402\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m   2403\u001b[0m         inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m-> 2404\u001b[0m         outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m   2407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(\n\u001b[1;32m   2408\u001b[0m     inputs, outputs, input_masks, build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/layers/rnn/lstm.py:751\u001b[0m, in \u001b[0;36mLSTM.call\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 (\n\u001b[1;32m    738\u001b[0m                     last_output,\n\u001b[1;32m    739\u001b[0m                     outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     runtime,\n\u001b[1;32m    743\u001b[0m                 ) \u001b[39m=\u001b[39m standard_lstm(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnormal_lstm_kwargs)\n\u001b[1;32m    744\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m             (\n\u001b[1;32m    746\u001b[0m                 last_output,\n\u001b[1;32m    747\u001b[0m                 outputs,\n\u001b[1;32m    748\u001b[0m                 new_h,\n\u001b[1;32m    749\u001b[0m                 new_c,\n\u001b[1;32m    750\u001b[0m                 runtime,\n\u001b[0;32m--> 751\u001b[0m             ) \u001b[39m=\u001b[39m lstm_with_backend_selection(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnormal_lstm_kwargs)\n\u001b[1;32m    753\u001b[0m     states \u001b[39m=\u001b[39m [new_h, new_c]\n\u001b[1;32m    755\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/layers/rnn/lstm.py:1356\u001b[0m, in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[39m# Call the normal LSTM impl and register the cuDNN impl function. The\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m     \u001b[39m# grappler will kick in during session execution to optimize the graph.\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m     last_output, outputs, new_h, new_c, runtime \u001b[39m=\u001b[39m defun_standard_lstm(\n\u001b[1;32m   1354\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m   1355\u001b[0m     )\n\u001b[0;32m-> 1356\u001b[0m     gru_lstm_utils\u001b[39m.\u001b[39;49mfunction_register(defun_gpu_lstm, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m   1358\u001b[0m \u001b[39mreturn\u001b[39;00m last_output, outputs, new_h, new_c, runtime\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/layers/rnn/gru_lstm_utils.py:259\u001b[0m, in \u001b[0;36mfunction_register\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m concrete_func \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39mget_concrete_function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    258\u001b[0m concrete_func\u001b[39m.\u001b[39madd_to_graph()\n\u001b[0;32m--> 259\u001b[0m concrete_func\u001b[39m.\u001b[39;49madd_gradient_functions_to_graph()\n\u001b[1;32m    260\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_func\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2115\u001b[0m, in \u001b[0;36mConcreteFunction.add_gradient_functions_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m   2112\u001b[0m   g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m   2113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_delayed_rewrite_functions\u001b[39m.\u001b[39mforward()\u001b[39m.\u001b[39madd_to_graph(g)\n\u001b[1;32m   2114\u001b[0m forward_function, backward_function \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 2115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_delayed_rewrite_functions\u001b[39m.\u001b[39;49mforward_backward())\n\u001b[1;32m   2116\u001b[0m forward_function\u001b[39m.\u001b[39madd_to_graph(g)\n\u001b[1;32m   2117\u001b[0m backward_function\u001b[39m.\u001b[39madd_to_graph(g)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:601\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m forward_backward \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m   \u001b[39mreturn\u001b[39;00m forward_backward\n\u001b[0;32m--> 601\u001b[0m forward, backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_forward_backward(num_doutputs)\n\u001b[1;32m    602\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_function_pairs[num_doutputs] \u001b[39m=\u001b[39m (forward, backward)\n\u001b[1;32m    603\u001b[0m \u001b[39mreturn\u001b[39;00m forward, backward\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:644\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m    642\u001b[0m   backwards_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mFuncGraph(\n\u001b[1;32m    643\u001b[0m       _backward_name(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39mname))\n\u001b[0;32m--> 644\u001b[0m   func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    645\u001b[0m       name\u001b[39m=\u001b[39;49mbackwards_graph\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    646\u001b[0m       python_func\u001b[39m=\u001b[39;49m_backprop_function,\n\u001b[1;32m    647\u001b[0m       args\u001b[39m=\u001b[39;49m[], kwargs\u001b[39m=\u001b[39;49m{},\n\u001b[1;32m    648\u001b[0m       signature\u001b[39m=\u001b[39;49msignature,\n\u001b[1;32m    649\u001b[0m       func_graph\u001b[39m=\u001b[39;49mbackwards_graph)\n\u001b[1;32m    650\u001b[0m   backwards_graph_captures \u001b[39m=\u001b[39m backwards_graph\u001b[39m.\u001b[39mexternal_captures\n\u001b[1;32m    651\u001b[0m   captures_from_forward \u001b[39m=\u001b[39m [\n\u001b[1;32m    652\u001b[0m       c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m backwards_graph_captures \u001b[39mif\u001b[39;00m\n\u001b[1;32m    653\u001b[0m       \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(c, ops\u001b[39m.\u001b[39mEagerTensor) \u001b[39mand\u001b[39;00m c\u001b[39m.\u001b[39mgraph \u001b[39mis\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:635\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward.<locals>._backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backprop_function\u001b[39m(\u001b[39m*\u001b[39mgrad_ys):\n\u001b[1;32m    634\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 635\u001b[0m     \u001b[39mreturn\u001b[39;00m gradients_util\u001b[39m.\u001b[39;49m_GradientsHelper(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    636\u001b[0m         trainable_outputs,\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph\u001b[39m.\u001b[39;49minputs,\n\u001b[1;32m    638\u001b[0m         grad_ys\u001b[39m=\u001b[39;49mgrad_ys,\n\u001b[1;32m    639\u001b[0m         src_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:695\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[1;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[1;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    696\u001b[0m                              \u001b[39mlambda\u001b[39;49;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[1;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:329\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m     xla_compile \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m xla_compile:\n\u001b[0;32m--> 329\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn()  \u001b[39m# Exit early\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m# together with the non-gradient computation.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:696\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[1;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[1;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0m                              \u001b[39mlambda\u001b[39;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[1;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/cond_v2.py:123\u001b[0m, in \u001b[0;36m_IfGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39m# Create grad functions that compute the gradient of the true/false forward\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m# graphs. These functions will capture tensors from the forward pass\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m true_grad_graph \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[1;32m    122\u001b[0m     true_graph, grads, util\u001b[39m.\u001b[39munique_grad_fn_name(true_graph\u001b[39m.\u001b[39mname))\n\u001b[0;32m--> 123\u001b[0m false_grad_graph \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[1;32m    124\u001b[0m     false_graph, grads, util\u001b[39m.\u001b[39;49munique_grad_fn_name(false_graph\u001b[39m.\u001b[39;49mname))\n\u001b[1;32m    126\u001b[0m \u001b[39m# Replaces output None grads with zeros if at least one branch has non-None\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m# grad at that index.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m _create_zeros_for_none_grads([true_graph, false_graph],\n\u001b[1;32m    129\u001b[0m                              [true_grad_graph, false_grad_graph])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/cond_v2.py:430\u001b[0m, in \u001b[0;36m_create_grad_func\u001b[0;34m(func_graph, grads, name)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_grad_func\u001b[39m(func_graph, grads, name):\n\u001b[1;32m    429\u001b[0m   \u001b[39m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m   \u001b[39mreturn\u001b[39;00m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    431\u001b[0m       name,\n\u001b[1;32m    432\u001b[0m       \u001b[39mlambda\u001b[39;49;00m: _grad_fn(func_graph, grads), [], {},\n\u001b[1;32m    433\u001b[0m       func_graph\u001b[39m=\u001b[39;49m_CondGradFuncGraph(name, func_graph))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/cond_v2.py:432\u001b[0m, in \u001b[0;36m_create_grad_func.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_grad_func\u001b[39m(func_graph, grads, name):\n\u001b[1;32m    429\u001b[0m   \u001b[39m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m   \u001b[39mreturn\u001b[39;00m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    431\u001b[0m       name,\n\u001b[0;32m--> 432\u001b[0m       \u001b[39mlambda\u001b[39;00m: _grad_fn(func_graph, grads), [], {},\n\u001b[1;32m    433\u001b[0m       func_graph\u001b[39m=\u001b[39m_CondGradFuncGraph(name, func_graph))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/cond_v2.py:421\u001b[0m, in \u001b[0;36m_grad_fn\u001b[0;34m(func_graph, grads)\u001b[0m\n\u001b[1;32m    415\u001b[0m   grad_ys\u001b[39m.\u001b[39mappend(grad_y)\n\u001b[1;32m    417\u001b[0m \u001b[39m# Build the gradient graph. Note that this builds the gradient computation of\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39m# func_graph in the current graph, which requires capturing tensors from\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m# in _resolve_grad_inputs.\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m result \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39;49m_GradientsHelper(\n\u001b[1;32m    422\u001b[0m     ys, func_graph\u001b[39m.\u001b[39;49minputs, grad_ys\u001b[39m=\u001b[39;49mgrad_ys,\n\u001b[1;32m    423\u001b[0m     src_graph\u001b[39m=\u001b[39;49mfunc_graph)\n\u001b[1;32m    425\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:695\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[1;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[1;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    696\u001b[0m                              \u001b[39mlambda\u001b[39;49;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[1;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:329\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m     xla_compile \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m xla_compile:\n\u001b[0;32m--> 329\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn()  \u001b[39m# Exit early\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m# together with the non-gradient computation.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gradients_util.py:696\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[1;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[1;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0m                              \u001b[39mlambda\u001b[39;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[1;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py:453\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    447\u001b[0m cond_grad_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    448\u001b[0m     grad_cond_name, grad_cond, loop_vars, {},\n\u001b[1;32m    449\u001b[0m     func_graph\u001b[39m=\u001b[39mutil\u001b[39m.\u001b[39mWhileCondFuncGraph(grad_cond_name))\n\u001b[1;32m    451\u001b[0m _check_num_inputs_outputs(cond_grad_graph, body_grad_graph, \u001b[39mlen\u001b[39m(loop_vars))\n\u001b[0;32m--> 453\u001b[0m outputs \u001b[39m=\u001b[39m _build_while_op(\n\u001b[1;32m    454\u001b[0m     loop_vars,\n\u001b[1;32m    455\u001b[0m     cond_grad_graph,\n\u001b[1;32m    456\u001b[0m     body_grad_graph,\n\u001b[1;32m    457\u001b[0m     output_shapes\u001b[39m=\u001b[39;49m[t\u001b[39m.\u001b[39;49mshape \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m body_grad_graph\u001b[39m.\u001b[39;49moutputs],\n\u001b[1;32m    458\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m    459\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m_grad\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m while_op\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    460\u001b[0m     num_original_outputs\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(body_grad_graph\u001b[39m.\u001b[39;49moutputs),\n\u001b[1;32m    461\u001b[0m     stateful_parallelism\u001b[39m=\u001b[39;49mstateful_parallelism)\n\u001b[1;32m    463\u001b[0m \u001b[39m# See comment in while_loop.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m outputs \u001b[39m=\u001b[39m [array_ops\u001b[39m.\u001b[39midentity(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py:508\u001b[0m, in \u001b[0;36m_build_while_op\u001b[0;34m(loop_vars, cond_graph, body_graph, output_shapes, parallel_iterations, name, num_original_outputs, stateful_parallelism)\u001b[0m\n\u001b[1;32m    506\u001b[0m   while_op\u001b[39m.\u001b[39m_body_graph \u001b[39m=\u001b[39m body_graph\n\u001b[1;32m    507\u001b[0m   \u001b[39mreturn\u001b[39;00m tensors\n\u001b[0;32m--> 508\u001b[0m \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mrun_as_function_for_tape_gradients(_make_op, loop_vars)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_util_v2.py:376\u001b[0m, in \u001b[0;36mrun_as_function_for_tape_gradients\u001b[0;34m(make_op, inputs)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m   \u001b[39mreturn\u001b[39;00m make_op(inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py:484\u001b[0m, in \u001b[0;36m_build_while_op.<locals>._make_op\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_op\u001b[39m(inputs):\n\u001b[0;32m--> 484\u001b[0m   while_op, tensors \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mget_op_and_outputs(op_fn(\n\u001b[1;32m    485\u001b[0m       inputs,\n\u001b[1;32m    486\u001b[0m       util\u001b[39m.\u001b[39;49mcreate_new_tf_function(cond_graph),\n\u001b[1;32m    487\u001b[0m       util\u001b[39m.\u001b[39;49mcreate_new_tf_function(body_graph),\n\u001b[1;32m    488\u001b[0m       output_shapes\u001b[39m=\u001b[39;49moutput_shapes,\n\u001b[1;32m    489\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m    490\u001b[0m       name\u001b[39m=\u001b[39;49mname))\n\u001b[1;32m    491\u001b[0m   _copy_handle_data(body_graph\u001b[39m.\u001b[39moutputs, tensors)\n\u001b[1;32m    492\u001b[0m   util\u001b[39m.\u001b[39mmaybe_set_lowering_attr(while_op)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_functional_ops.py:1007\u001b[0m, in \u001b[0;36mstateless_while\u001b[0;34m(input, cond, body, output_shapes, parallel_iterations, name)\u001b[0m\n\u001b[1;32m   1005\u001b[0m   parallel_iterations \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m   1006\u001b[0m parallel_iterations \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_int(parallel_iterations, \u001b[39m\"\u001b[39m\u001b[39mparallel_iterations\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1007\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m   1008\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mStatelessWhile\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, cond\u001b[39m=\u001b[39;49mcond, body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m   1009\u001b[0m                         output_shapes\u001b[39m=\u001b[39;49moutput_shapes,\n\u001b[1;32m   1010\u001b[0m                         parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1011\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m   1012\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[1;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:733\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    731\u001b[0m   \u001b[39mif\u001b[39;00m ctxt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ctxt, \u001b[39m\"\u001b[39m\u001b[39mAddValue\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    732\u001b[0m     inp \u001b[39m=\u001b[39m ctxt\u001b[39m.\u001b[39mAddValue(inp)\n\u001b[0;32m--> 733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcapture(inp)\n\u001b[1;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m    735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(FuncGraph, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:800\u001b[0m, in \u001b[0;36mFuncGraph.capture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    790\u001b[0m       \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mInaccessibleTensorError(\n\u001b[1;32m    791\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m!r}\u001b[39;00m\u001b[39m is out of scope and cannot be used here. Use return \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mvalues, explicit Python locals or TensorFlow collections to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    797\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe tensor \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m!r}\u001b[39;00m\u001b[39m cannot be accessed from \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, because \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    798\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mit was defined in \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39mgraph\u001b[39m}\u001b[39;00m\u001b[39m, which is out of scope.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    799\u001b[0m     inner_graph \u001b[39m=\u001b[39m inner_graph\u001b[39m.\u001b[39mouter_graph\n\u001b[0;32m--> 800\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_helper(tensor, name)\n\u001b[1;32m    801\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/cond_v2.py:1017\u001b[0m, in \u001b[0;36m_CondGradFuncGraph._capture_helper\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m   1014\u001b[0m   optional \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrapped_intermediates[tensor_id]\n\u001b[1;32m   1015\u001b[0m   captured_optional \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(_CondGradFuncGraph,\n\u001b[1;32m   1016\u001b[0m                             \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_capture_helper(optional, name)\n\u001b[0;32m-> 1017\u001b[0m   captured_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49moptional_get_value(\n\u001b[1;32m   1018\u001b[0m       captured_optional, [tensor\u001b[39m.\u001b[39;49mdtype], [tensor\u001b[39m.\u001b[39;49mshape])[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1020\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indirect_captures[tensor_id] \u001b[39m=\u001b[39m captured_tensor\n\u001b[1;32m   1021\u001b[0m \u001b[39mreturn\u001b[39;00m captured_tensor\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:4658\u001b[0m, in \u001b[0;36moptional_get_value\u001b[0;34m(optional, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   4654\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   4655\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mExpected list for \u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput_shapes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4656\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39moptional_get_value\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Op, not \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m output_shapes)\n\u001b[1;32m   4657\u001b[0m output_shapes \u001b[39m=\u001b[39m [_execute\u001b[39m.\u001b[39mmake_shape(_s, \u001b[39m\"\u001b[39m\u001b[39moutput_shapes\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m _s \u001b[39min\u001b[39;00m output_shapes]\n\u001b[0;32m-> 4658\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m   4659\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mOptionalGetValue\u001b[39;49m\u001b[39m\"\u001b[39;49m, optional\u001b[39m=\u001b[39;49moptional, output_types\u001b[39m=\u001b[39;49moutput_types,\n\u001b[1;32m   4660\u001b[0m                           output_shapes\u001b[39m=\u001b[39;49moutput_shapes, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   4661\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m   4662\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[1;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[1;32m   3801\u001b[0m       node_def,\n\u001b[1;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2105\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[1;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[1;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1974\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[39m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m \u001b[39m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m \u001b[39mif\u001b[39;00m extract_traceback:\n\u001b[0;32m-> 1974\u001b[0m   tf_stack\u001b[39m.\u001b[39;49mextract_stack_for_op(c_op, stacklevel\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[1;32m   1976\u001b[0m \u001b[39mreturn\u001b[39;00m c_op\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/tf_stack.py:180\u001b[0m, in \u001b[0;36mextract_stack_for_op\u001b[0;34m(c_op, stacklevel)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39m# N.B ExtractStack in tf_stack.cc will drop this frame prior to\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m# traversing the stack.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m thread_key \u001b[39m=\u001b[39m _get_thread_key()\n\u001b[0;32m--> 180\u001b[0m _tf_stack\u001b[39m.\u001b[39;49mextract_stack_for_op(\n\u001b[1;32m    181\u001b[0m     _source_mapper_stacks[thread_key][\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49minternal_map,\n\u001b[1;32m    182\u001b[0m     _source_filter_stacks[thread_key][\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49minternal_set, c_op, stacklevel)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make a route with a grade?\n",
    "from share.moonboard_util import MoonBoardRoute\n",
    "from MoonBoardRNN.GradeNet.grade_net import GradeNet\n",
    "from MoonBoardRNN.plotting import plot_problem\n",
    "\n",
    "TARGET = 'V5'\n",
    "net = GradeNet()\n",
    "while True:\n",
    "    try:\n",
    "        route = MoonBoardRoute.make_random_valid()\n",
    "        grade = net.grade_route(route)\n",
    "        if grade == TARGET:\n",
    "            break\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "print(route)\n",
    "print(f'Grade: {grade}')\n",
    "plot_problem(route.to_strings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Beamer search, the most possible hand sequence and the successRate:\n",
      "['F5', 'F5', 'C7', 'D9', 'B11', 'E13', 'B15', 'D18']\n",
      "[0, 0, 1, 2, 3, 4, 5, 7] ['LH', 'RH', 'LH', 'RH', 'LH', 'RH', 'LH', 'RH'] [83.49613078]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "V6\n"
     ]
    }
   ],
   "source": [
    "# Test Route - PULL YASELF UP! YAY\n",
    "\n",
    "from share.moonboard_util import MoonBoardRoute\n",
    "from MoonBoardRNN.GradeNet.grade_net import GradeNet\n",
    "\n",
    "start_holds = ['F5']\n",
    "end_holds = ['D18']\n",
    "others = ['C7', 'D9', 'B11', 'E13', 'B15', 'D18']\n",
    "route = MoonBoardRoute.from_hold_strings(start_holds=start_holds, mid_holds=others, end_holds=end_holds)\n",
    "# x_vecs = route_to_x_vectors(route)\n",
    "# matrix = x_vectors_to_matrix(x_vecs)\n",
    "\n",
    "print('')\n",
    "# x_vectors = route_to_x_vectors(route)\n",
    "net = GradeNet()\n",
    "grade = net.grade_route(route)\n",
    "print(grade)\n",
    "#print(x_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oute(route)\n",
    "print(grade)\n",
    "#print(x_vectors)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
