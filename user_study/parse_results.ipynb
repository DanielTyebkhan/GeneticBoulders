{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "def read_valid_results(path):\n",
    "    valid_res = []\n",
    "    with open(path, 'r') as file:\n",
    "        reader = DictReader(file)\n",
    "        next(reader)\n",
    "        next(reader)\n",
    "        for item in reader:\n",
    "            if item['Status'] != 'Survey Preview' and item['Q6'] != '' and item['Screen 1'] == 'Yes' and item['Screen 2'] == '40':\n",
    "                valid_res.append(item)\n",
    "    return valid_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 valid responses\n",
      "47 reliable responses\n",
      "Calibration: [(13, 0.6), (13, 0.5), (12, 0.6), (11, 0.8), (11, 0.6), (10, 0.8), (10, 0.7), (10, 0.7), (10, 0.6), (10, 0.5), (9, 0.8888888888888888), (9, 0.6666666666666666), (9, 0.6666666666666666), (9, 0.6666666666666666), (9, 0.6666666666666666), (9, 0.5555555555555556), (8, 1.0), (8, 0.875), (8, 0.75), (8, 0.75), (8, 0.75), (8, 0.625), (8, 0.5), (8, 0.5), (8, 0.5), (7, 0.8571428571428571), (7, 0.8571428571428571), (7, 0.7142857142857143), (7, 0.7142857142857143), (7, 0.7142857142857143), (7, 0.7142857142857143), (7, 0.5714285714285714), (7, 0.5714285714285714), (7, 0.5714285714285714), (7, 0.5714285714285714), (7, 0.5714285714285714), (6, 0.8333333333333334), (6, 0.6666666666666666), (5, 1.0), (5, 1.0), (5, 0.8), (5, 0.8), (5, 0.8), (4, 1.0), (4, 1.0), (4, 0.75), (4, 0.5)]\n",
      "Generated: [(13, 0.85), (13, 0.45), (12, 0.7), (11, 0.85), (11, 0.4), (10, 0.85), (10, 0.85), (10, 0.65), (10, 0.6), (10, 0.55), (9, 0.8888888888888888), (9, 0.7777777777777778), (9, 0.7777777777777778), (9, 0.7222222222222222), (9, 0.6666666666666666), (9, 0.3888888888888889), (8, 0.8125), (8, 0.8125), (8, 0.8125), (8, 0.8125), (8, 0.75), (8, 0.75), (8, 0.6875), (8, 0.625), (8, 0.4375), (7, 1.0), (7, 0.8571428571428571), (7, 0.7857142857142857), (7, 0.7857142857142857), (7, 0.7857142857142857), (7, 0.7142857142857143), (7, 0.6428571428571429), (7, 0.5714285714285714), (7, 0.5), (7, 0.42857142857142855), (7, 0.35714285714285715), (6, 0.9166666666666666), (6, 0.5), (5, 1.0), (5, 0.9), (5, 0.8), (5, 0.8), (5, 0.7), (4, 0.875), (4, 0.875), (4, 0.625), (4, 0.25)]\n",
      "0.7051587301587302\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "from image_link_mapping import IMAGE_LINKS\n",
    "from survey_response import SurveyResponse\n",
    "from collections import defaultdict\n",
    "path = '/home/tyebkhad/GeneticBoulders/user_study/Evolving MoonBoard Routes_February 20, 2023_20.45.csv'\n",
    "valid_res = read_valid_results(path)\n",
    "calibration_indices = [i for i, v in enumerate(IMAGE_LINKS) if 'calibrate' in v]\n",
    "\n",
    "responses = [SurveyResponse(res) for res in valid_res]\n",
    "print(len(responses), 'valid responses')\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "reliable_responses = [r for r in responses if (p := r.perc_calibrated_gradeable()) and p >= THRESHOLD]\n",
    "rr_dict = defaultdict(list)\n",
    "for r in reliable_responses:\n",
    "    rr_dict[r.max_climbed].append(r)\n",
    "print(len(reliable_responses), 'reliable responses')\n",
    "calib_percs = sorted([(r.max_climbed, r.perc_calibrated_gradeable()) for r in reliable_responses], reverse=True)\n",
    "gen_percs = sorted([(r.max_climbed, r.perc_generated_gradeable()) for r in reliable_responses], reverse=True)\n",
    "print('Calibration:', calib_percs)\n",
    "print('Generated:', gen_percs)\n",
    "print(mean(i[1] for i in gen_percs))\n",
    "\n",
    "# look at correlation between max grade and being accurate\n",
    "# \n",
    "\n",
    "# print(sorted((r.max_gradeable() for r in responses), reverse=True))\n",
    "# percs = [r.perc_calibrated_gradeable() for r in responses]\n",
    "# print(sorted(percs, reverse=True))\n",
    "# for resp in responses:\n",
    "#     print(resp.perc_calibrated_gradeable())\n",
    "\n",
    "# got_v4 = []\n",
    "# for item in valid_res:\n",
    "#     v4_resp = item['17_Q10']\n",
    "#     if 'V4' in v4_resp or 'V5' in v4_resp:\n",
    "#         got_v4.append(item)\n",
    "# print(len(got_v4))\n",
    "# for r in got_v4:\n",
    "#     print(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording\n",
    "- 52 valid responses\n",
    "### Allowing +- 1 in grade\n",
    "- 16 responses with >= 50% correct calibration at or below their max climbing grade\n",
    "    - these responses agreed with predicted grade 30% of the time\n",
    "### Allowing +- 2 in grade\n",
    "- 35 responses with >= 50% correct calib at or below max\n",
    "    - these responses agreed with predicted grade about 55% of the time\n",
    "### allowing +- 3\n",
    "- 47 response are valid \n",
    "    - agree 71% of the time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
